{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Dom Ruan Suzano\n",
    "\n",
    "Nome: Hudson Monteiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualiza√ß√£o\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando algumas bibliotecas para limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dom\n",
      "[nltk_data]     Ruan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\dom ruan\\anaconda3\\lib\\site-packages (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "!pip install emoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirma√ß√£o do diret√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Dom Ruan\\2¬∞ Semestre Eng\\C.Dados\\Projeto_1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise do Banco de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pepsi.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>namoral n tem refrigerante melhor q o da pepsi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a pepsi fez o logo baseado na gravidade sobre ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@erongranth neo qu√≠mica, kalunga e pepsi acho ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mataria por um refri geladinho agr mas so tem ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@pitta_ai e dion√≠sio, o cara viciado em pepsi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@jujuubuenoo pepsi¬Æ geladinha tem um gostinho ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>escreva isso ou aquilo usando a tag #sonkezsen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@elitavres pepsi¬Æ √© tudo de bom, fala a√≠! üòâüíô‚ù§</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@pepsibr pq as pepsi ta vindo tao sem gas????</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ele s√≥ queria uma pepsi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  namoral n tem refrigerante melhor q o da pepsi...           1\n",
       "1  a pepsi fez o logo baseado na gravidade sobre ...           1\n",
       "2  @erongranth neo qu√≠mica, kalunga e pepsi acho ...           1\n",
       "3  mataria por um refri geladinho agr mas so tem ...           1\n",
       "4      @pitta_ai e dion√≠sio, o cara viciado em pepsi           1\n",
       "5  @jujuubuenoo pepsi¬Æ geladinha tem um gostinho ...           0\n",
       "6  escreva isso ou aquilo usando a tag #sonkezsen...           0\n",
       "7      @elitavres pepsi¬Æ √© tudo de bom, fala a√≠! üòâüíô‚ù§           0\n",
       "8      @pepsibr pq as pepsi ta vindo tao sem gas????           1\n",
       "9                            ele s√≥ queria uma pepsi           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@trishteza uma pepsi¬Æ √© coisa de outro mundo, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cultwolverine pepsi arena ia ficar muito mais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@alisonbap pepsi e melhor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realizando uma pesquisa cient√≠fica com meus am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pizza tomando minha pepsi com lim√£o melhorou o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relev√¢ncia\n",
       "0  @trishteza uma pepsi¬Æ √© coisa de outro mundo, ...           0\n",
       "1  @cultwolverine pepsi arena ia ficar muito mais...           1\n",
       "2                          @alisonbap pepsi e melhor           1\n",
       "3  realizando uma pesquisa cient√≠fica com meus am...           0\n",
       "4  pizza tomando minha pepsi com lim√£o melhorou o...           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nosso produto √© o refrigerante pepsi,um refrigerante norte-americano com sabor de cola, consideramos como relevante os tweets que falavam bem ou mal tanto da marca como do produto, al√©m disso exce√ß√µes  como tweets feito pelo twitter da pepsi foram considerados irrelevantes mesmo que falassem bem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo fun√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words(lista):\n",
    "    nova_lista = []\n",
    "    for a in lista:\n",
    "        if a not in stopwords.words('portuguese'):\n",
    "            nova_lista.append(a)\n",
    "    return nova_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa os tweets, tira os pontos desnecess√°rios\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[¬Æ,!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_emoji(text):\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(text))\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retira o arroba(@)\n",
    "def limpa_arrobas(texto):\n",
    "    novo_texto = []\n",
    "    for t in texto.split():\n",
    "        if t[0] != '@':\n",
    "            novo_texto.append(t)\n",
    "    novo_texto = ' '.join(novo_texto)\n",
    "    return novo_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa os links do tweet\n",
    "def limpa_links(texto):\n",
    "    novo_texto = []\n",
    "    for t in texto.split():\n",
    "        if len(t) > 4 and t[0:4] != 'http':\n",
    "            novo_texto.append(t)\n",
    "    novo_texto = ' '.join(novo_texto)\n",
    "    return novo_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fun√ß√£o que deixa todas as letras de uma frase minusc√∫las e separa ela em uma lista\n",
    "def tokenization(string):\n",
    "    return string.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_texto(texto):\n",
    "    texto = limpa_arrobas(limpa_links(separa_emoji(cleanup(texto))))\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando num texto\n",
    "for a in range(300):\n",
    "    texto = train.loc[a,\"Treinamento\"]\n",
    "    texto = str(texto)\n",
    "    texto = limpa_texto(texto)\n",
    "    train.loc[a,\"Treinamento\"] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(200):\n",
    "    texto = test.loc[a,\"Teste\"]\n",
    "    texto = str(texto)\n",
    "    texto = limpa_texto(texto)\n",
    "    test.loc[a,\"Teste\"] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar palavras em vari√°veis categ√≥ricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando as fun√ß√µes de limpeza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevantes\n",
    "\n",
    "frequ√™ncias Absolutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Treinamento                                                                        Relev√¢ncia  Modelo\n",
       "pepsi                                                                              1           1         9\n",
       "pepsi melhor                                                                       1           1         4\n",
       "√∫nica coisa compensou pepsi infelizmente daquela garrafinha                        1           1         1\n",
       "gosto pepsi pepsi twist outro n√≠vel otimo refrigerante                             1           1         1\n",
       "gostar pepsi negar d√©cadas fazem campanhas marketing ser√£o lembradas sempre delas  1           1         1\n",
       "                                                                                                        ..\n",
       "pepsi melhor passagem                                                              1           1         1\n",
       "pepsi melhor dependente tratar                                                     1           1         1\n",
       "pepsi maracuj√°                                                                     1           1         1\n",
       "pepsi maior melhor                                                                 1           1         1\n",
       "acabei fazer descoberta pepsi black a√ß√∫car melhor                                  1           1         1\n",
       "Length: 148, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relevantes \n",
    "rel = train[train['Relev√¢ncia'] ==1]\n",
    "\n",
    "# frequencia absoluta\n",
    "rel_freq_abs = rel.value_counts()\n",
    "rel_freq_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevantes\n",
    "\n",
    "frequ√™ncias Absolutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Treinamento                                        Relev√¢ncia\n",
       "pepsi                                              0             7\n",
       "triangular bread                                   0             3\n",
       "minha buceta gosto pepsi                           0             2\n",
       "√©poca √≥culos festa pepsi achando arrasando         0             1\n",
       "ent√£o psic√≥logo pepsi pessoas pensam sinceramente  0             1\n",
       "                                                                ..\n",
       "pepsi gtgtgtgtgt respeito tijucano                 0             1\n",
       "pepsi kkkkkk                                       0             1\n",
       "pepsi nossa reles compreens√£o                      0             1\n",
       "pepsi pegar largar                                 0             1\n",
       "                                                   0             1\n",
       "Length: 132, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Irrelevantes\n",
    "irr = train[train['Relev√¢ncia'] ==0]\n",
    "\n",
    "# Frequancia absoluta\n",
    "irr_freq_abs = irr.value_counts()\n",
    "\n",
    "irr_freq_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Relevantes\n",
    "palavras_relevantes = rel['Treinamento']\n",
    "relev_string = ''\n",
    "for tweet in palavras_relevantes:\n",
    "    relev_string += ' ' + tweet\n",
    "palav_relev = stop_words(tokenization(relev_string))\n",
    "\n",
    "# Irrelevantes\n",
    "palavras_irrelevantes = irr['Treinamento']\n",
    "irrelev_string = ''\n",
    "for tweet in palavras_irrelevantes:\n",
    "    irrelev_string += ' ' + tweet\n",
    "palav_irrelev = stop_words(tokenization(irrelev_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd Series de todas as palavras\n",
    "todas_palavras = palav_relev + palav_irrelev\n",
    "serie_todas_palavras = pd.Series(todas_palavras)\n",
    "\n",
    "# frequencia todas palavras relativa\n",
    "tabela_todas_palavras_relativa = serie_todas_palavras.value_counts(True)\n",
    "tabela_todas_palavras_relativa\n",
    "\n",
    "#frequencia de Todas palavras absolutas\n",
    "tabela_todas_palavras_abs = serie_todas_palavras.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras sem repeti√ß√£o\n",
    "palavras_sem_repeticao = list(set(todas_palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabela relevantes e irrelevantes\n",
    "serie_relevantes = pd.Series(palav_relev)\n",
    "serie_irrelevantes = pd.Series(palav_irrelev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencias relativas relevantes e irrelevantes\n",
    "tabela_relevantes_relativa = serie_relevantes.value_counts(True)\n",
    "tabela_irrelevantes_relativa = serie_irrelevantes.value_counts(True)\n",
    "\n",
    "rel_freq_abs = serie_relevantes.value_counts()\n",
    "irr_freq_abs = serie_irrelevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " # texto explicando as probabilides que queremos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilides iniciais\n",
    "\n",
    "# calculando a probabilidade de ser relevante e irrelente\n",
    "P_rel = len(palav_relev)/len(todas_palavras)\n",
    "P_irr = len(palav_irrelev)/len(todas_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto explicando...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingenuidade de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto explicando...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suaviza√ß√£o de Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contextualiza√ß√£o..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suaviza√ß√£o de Laplace para corrigir possiveis palavras fora da minha base de dados\n",
    "def smoothing(palavra, frequencia_absoluta, palavras_sem_repeticao, relevancia, alpha=1):\n",
    "    resultado = 0\n",
    "    try:\n",
    "        absoluta = frequencia_absoluta[palavra]\n",
    "    except:\n",
    "        absoluta = 0 #Se a palavra n√£o estiver na lista retorna 0\n",
    "    if relevancia == 'relevante':\n",
    "        resultado = (absoluta + alpha)/(len(palav_relev)+alpha*len(palavras_sem_repeticao))\n",
    "    elif relevancia == 'irrelevante':\n",
    "        resultado = (absoluta + alpha)/(len(palav_irrelev)+alpha*len(palavras_sem_repeticao))\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√°lculo das Probabilidades condicionais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade para fazer a desigualdade \n",
    "def prob(relevancia,frase):\n",
    "    if relevancia == 'relevante':\n",
    "        probTweetdadoR = 1\n",
    "        for a in frase.split():\n",
    "            probTweetdadoR *= smoothing(a, rel_freq_abs, palavras_sem_repeticao, relevancia)\n",
    "        probRdadoTweet = P_rel * probTweetdadoR\n",
    "        return probRdadoTweet\n",
    "    elif relevancia == 'irrelevante':\n",
    "        probTweetdadoI = 1\n",
    "        for b in frase.split():\n",
    "            probTweetdadoI *= smoothing(b, irr_freq_abs, palavras_sem_repeticao, relevancia)\n",
    "        probIdadoTweet = P_irr * probTweetdadoI\n",
    "        return probIdadoTweet\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo de naive para comparar as probabilidades\n",
    "def Naive(tweet):\n",
    "    if prob('relevante',tweet) > prob('irrelevante',tweet):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Modelo\"]=train[\"Treinamento\"].apply(Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th>Modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>namoral refrigerante melhor pepsip existe nenhum</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pepsi baseado gravidade sobre pepsi sentido ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qu√≠mica kalunga pepsi patrocinadores ficaram b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mataria refri geladinho pepsi geladeira</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dion√≠sio viciado pepsi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>queria fazer drink laranja beber pepsi mesmo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>minha falando pepsi caber geladeira ‚Äúgordinha‚Äù...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>triangular bread</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>acordei enjoo kerelho minha desculpa tomar cop...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>pessoas pepsi kkkkkk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relev√¢ncia  Modelo\n",
       "0     namoral refrigerante melhor pepsip existe nenhum           1       1\n",
       "1    pepsi baseado gravidade sobre pepsi sentido ne...           1       1\n",
       "2    qu√≠mica kalunga pepsi patrocinadores ficaram b...           1       1\n",
       "3              mataria refri geladinho pepsi geladeira           1       1\n",
       "4                               dion√≠sio viciado pepsi           1       1\n",
       "..                                                 ...         ...     ...\n",
       "295       queria fazer drink laranja beber pepsi mesmo           0       0\n",
       "296  minha falando pepsi caber geladeira ‚Äúgordinha‚Äù...           0       0\n",
       "297                                   triangular bread           0       0\n",
       "298  acordei enjoo kerelho minha desculpa tomar cop...           1       1\n",
       "299                               pessoas pepsi kkkkkk           0       0\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
