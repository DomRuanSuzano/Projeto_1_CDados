{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Dom Ruan Suzano\n",
    "\n",
    "Nome: Hudson Monteiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualiza√ß√£o\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando algumas bibliotecas para limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dom\n",
      "[nltk_data]     Ruan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\dom ruan\\anaconda3\\lib\\site-packages (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "!pip install emoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirma√ß√£o do diret√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Dom Ruan\\2¬∞ Semestre Eng\\C.Dados\\Projeto_1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise do Banco de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pepsi.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>namoral n tem refrigerante melhor q o da pepsi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a pepsi fez o logo baseado na gravidade sobre ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@erongranth neo qu√≠mica, kalunga e pepsi acho ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mataria por um refri geladinho agr mas so tem ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@pitta_ai e dion√≠sio, o cara viciado em pepsi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@jujuubuenoo pepsi¬Æ geladinha tem um gostinho ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>escreva isso ou aquilo usando a tag #sonkezsen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@elitavres pepsi¬Æ √© tudo de bom, fala a√≠! üòâüíô‚ù§</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@pepsibr pq as pepsi ta vindo tao sem gas????</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ele s√≥ queria uma pepsi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  namoral n tem refrigerante melhor q o da pepsi...           1\n",
       "1  a pepsi fez o logo baseado na gravidade sobre ...           1\n",
       "2  @erongranth neo qu√≠mica, kalunga e pepsi acho ...           1\n",
       "3  mataria por um refri geladinho agr mas so tem ...           1\n",
       "4      @pitta_ai e dion√≠sio, o cara viciado em pepsi           1\n",
       "5  @jujuubuenoo pepsi¬Æ geladinha tem um gostinho ...           0\n",
       "6  escreva isso ou aquilo usando a tag #sonkezsen...           0\n",
       "7      @elitavres pepsi¬Æ √© tudo de bom, fala a√≠! üòâüíô‚ù§           0\n",
       "8      @pepsibr pq as pepsi ta vindo tao sem gas????           1\n",
       "9                            ele s√≥ queria uma pepsi           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@trishteza uma pepsi¬Æ √© coisa de outro mundo, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cultwolverine pepsi arena ia ficar muito mais...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@alisonbap pepsi e melhor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realizando uma pesquisa cient√≠fica com meus am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pizza tomando minha pepsi com lim√£o melhorou o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relev√¢ncia\n",
       "0  @trishteza uma pepsi¬Æ √© coisa de outro mundo, ...           0\n",
       "1  @cultwolverine pepsi arena ia ficar muito mais...           1\n",
       "2                          @alisonbap pepsi e melhor           1\n",
       "3  realizando uma pesquisa cient√≠fica com meus am...           0\n",
       "4  pizza tomando minha pepsi com lim√£o melhorou o...           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nosso produto √© o refrigerante pepsi,um refrigerante norte-americano com sabor de cola, consideramos como relevante os tweets que falavam bem ou mal tanto da marca como do produto, al√©m disso exce√ß√µes  como tweets feito pelo twitter da pepsi foram considerados irrelevantes mesmo que falassem bem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo fun√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words(lista):\n",
    "    nova_lista = []\n",
    "    for a in lista:\n",
    "        if a not in stopwords.words('portuguese'):\n",
    "            nova_lista.append(a)\n",
    "    return nova_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa os tweets, tira os pontos desnecess√°rios\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[¬Æ,!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_emoji(text):\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(text))\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retira o arroba(@)\n",
    "def limpa_arrobas(texto):\n",
    "    novo_texto = []\n",
    "    for t in texto.split():\n",
    "        if t[0] != '@':\n",
    "            novo_texto.append(t)\n",
    "    novo_texto = ' '.join(novo_texto)\n",
    "    return novo_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa os links do tweet\n",
    "def limpa_links(texto):\n",
    "    novo_texto = []\n",
    "    for t in texto.split():\n",
    "        if len(t) > 4 and t[0:4] != 'http':\n",
    "            novo_texto.append(t)\n",
    "    novo_texto = ' '.join(novo_texto)\n",
    "    return novo_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fun√ß√£o que deixa todas as letras de uma frase minusc√∫las e separa ela em uma lista\n",
    "def tokenization(string):\n",
    "    return string.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_texto(texto):\n",
    "    texto = limpa_arrobas(limpa_links(separa_emoji(cleanup(texto))))\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando num texto\n",
    "for a in range(300):\n",
    "    texto = train.loc[a,\"Treinamento\"]\n",
    "    texto = str(texto)\n",
    "    texto = limpa_texto(texto)\n",
    "    train.loc[a,\"Treinamento\"] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(200):\n",
    "    texto = test.loc[a,\"Teste\"]\n",
    "    texto = str(texto)\n",
    "    texto = limpa_texto(texto)\n",
    "    test.loc[a,\"Teste\"] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar palavras em vari√°veis categ√≥ricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando as fun√ß√µes de limpeza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevantes\n",
    "\n",
    "frequ√™ncias Absolutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Treinamento                                                                        Relev√¢ncia\n",
       "pepsi                                                                              1             9\n",
       "pepsi melhor                                                                       1             4\n",
       "√∫nica coisa compensou pepsi infelizmente daquela garrafinha                        1             1\n",
       "gosto pepsi pepsi twist outro n√≠vel otimo refrigerante                             1             1\n",
       "gostar pepsi negar d√©cadas fazem campanhas marketing ser√£o lembradas sempre delas  1             1\n",
       "                                                                                                ..\n",
       "pepsi melhor passagem                                                              1             1\n",
       "pepsi melhor dependente tratar                                                     1             1\n",
       "pepsi maracuj√°                                                                     1             1\n",
       "pepsi maior melhor                                                                 1             1\n",
       "acabei fazer descoberta pepsi black a√ß√∫car melhor                                  1             1\n",
       "Length: 148, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relevantes \n",
    "rel = train[train['Relev√¢ncia'] ==1]\n",
    "\n",
    "# frequencia absoluta\n",
    "rel_freq_abs = rel.value_counts()\n",
    "rel_freq_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevantes\n",
    "\n",
    "frequ√™ncias Absolutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Treinamento                                        Relev√¢ncia\n",
       "pepsi                                              0             7\n",
       "triangular bread                                   0             3\n",
       "minha buceta gosto pepsi                           0             2\n",
       "√©poca √≥culos festa pepsi achando arrasando         0             1\n",
       "ent√£o psic√≥logo pepsi pessoas pensam sinceramente  0             1\n",
       "                                                                ..\n",
       "pepsi gtgtgtgtgt respeito tijucano                 0             1\n",
       "pepsi kkkkkk                                       0             1\n",
       "pepsi nossa reles compreens√£o                      0             1\n",
       "pepsi pegar largar                                 0             1\n",
       "                                                   0             1\n",
       "Length: 132, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Irrelevantes\n",
    "irr = train[train['Relev√¢ncia'] ==0]\n",
    "\n",
    "# Frequancia absoluta\n",
    "irr_freq_abs = irr.value_counts()\n",
    "\n",
    "irr_freq_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Relevantes\n",
    "palavras_relevantes = rel['Treinamento']\n",
    "relev_string = ''\n",
    "for tweet in palavras_relevantes:\n",
    "    relev_string += ' ' + tweet\n",
    "palav_relev = stop_words(tokenization(relev_string))\n",
    "\n",
    "# Irrelevantes\n",
    "palavras_irrelevantes = irr['Treinamento']\n",
    "irrelev_string = ''\n",
    "for tweet in palavras_irrelevantes:\n",
    "    irrelev_string += ' ' + tweet\n",
    "palav_irrelev = stop_words(tokenization(irrelev_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd Series de todas as palavras\n",
    "todas_palavras = palav_relev + palav_irrelev\n",
    "serie_todas_palavras = pd.Series(todas_palavras)\n",
    "\n",
    "# frequencia todas palavras relativa\n",
    "tabela_todas_palavras_relativa = serie_todas_palavras.value_counts(True)\n",
    "tabela_todas_palavras_relativa\n",
    "\n",
    "#frequencia de Todas palavras absolutas\n",
    "tabela_todas_palavras_abs = serie_todas_palavras.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras sem repeti√ß√£o\n",
    "palavras_sem_repeticao = list(set(todas_palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabela relevantes e irrelevantes\n",
    "serie_relevantes = pd.Series(palav_relev)\n",
    "serie_irrelevantes = pd.Series(palav_irrelev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencias relativas relevantes e irrelevantes\n",
    "tabela_relevantes_relativa = serie_relevantes.value_counts(True)\n",
    "tabela_irrelevantes_relativa = serie_irrelevantes.value_counts(True)\n",
    "\n",
    "rel_freq_abs = serie_relevantes.value_counts()\n",
    "irr_freq_abs = serie_irrelevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " # texto explicando as probabilides que queremos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilides iniciais\n",
    "\n",
    "# calculando a probabilidade de ser relevante e irrelente\n",
    "P_rel = len(palav_relev)/len(todas_palavras)\n",
    "P_irr = len(palav_irrelev)/len(todas_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes e Suaviza√ß√£o de Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo ‚ÄúNaive Bayes‚Äù √© um classificador probabil√≠stico baseado no ‚ÄúTeorema de Bayes‚Äù, o qual foi criado por Thomas Bayes (1701 - 1761) para tentar provar a exist√™ncia de Deus.\n",
    "\n",
    "Atualmente, esse algoritmo √© utilizado na √°rea de $Data Science$ tendo a funcionalidade de categorizar textos com base na frequ√™ncia de palavras que aparecem no mesmo.\n",
    "\n",
    "A melhor parte deste algoritmo vem da sua ingenuidade ($naive$ em ingl√™s)! Com isso n√≥s queremos dizer que ele desconsidera a correla√ß√£o de palavras(vari√°veis) e trata elas de forma independente.\n",
    "\n",
    "Mas agora vamos as contas! Como de fato n√≥s podemos utilizar esse algoritmo na programa√ß√£o? Bom, trazendo esse projeto como exemplo, temos:\n",
    "\n",
    "O teorema de Naive Bayes consiste em calcular\n",
    "\n",
    "probabilidades partindo de eventos posteriores (ser relevante, dado que foi classificado como relevante), multiplicando pela probabilidade de o tweet ser de fato relevante pela probabilidade ‚Äúser classificado como relevante, dado que o tweet √© relevante‚Äù. De forma an√°loga a isso se aplica para os tweets irrelevantes.\n",
    "\n",
    "Como a soma dessas probabilidades para os tweets relevantes e irrelevantes deve resultar em 1, √© necess√°rio normalizar esses valores e isso √© feito dividindo cada um desses pela soma de ambos.\n",
    "\n",
    "Mas agora vamos mostrar isso com um pouco de matem√°tica:\n",
    "\n",
    "Definindo algumas probabilidades:\n",
    "\n",
    "\n",
    "$P(Tweet|Relevante)$: probabilidade de classificar o tweet como relevante dado que o tweet √© relevante;\n",
    "$P(Tweet|Irrelevante)$: probabilidade de classificar o tweet como irrelevante dado que o twwet √© irrelevante;\n",
    "$P(Relevante)$: probabilidade do tweet ser relevante;\n",
    "$P(Irrelevante)$: probabilidade do tweet ser irrelevante;\n",
    "$P(Tweet)$: probabilidade de um tweet qualquer ocorrer.\n",
    "$$P(Relevante|Tweet) = \\frac{P(Tweet|Relevente) P(Relevante)}{P(Tweet)}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "O processo √© an√°logo para $P(Irrelevante|tweet)$:\n",
    "\n",
    "\n",
    "\n",
    "$$P(Irrelevante|Tweet) = \\frac{P(Tweet|Irrelevante) P(Irrelevante)}{P(Tweet)}$$\n",
    "\n",
    "\n",
    "Mas como podemos calcular cada um desses termos para saber se o tweet √© relevante ou irrelevante?\n",
    "Bom, primeiramente vamos calcular as seguintes probabilidades: $P(Relevante)$ e $P(Irrelevante)$.\n",
    "\n",
    "Quantidade de palavras dos tweets relevantes: $Qr$\n",
    "Quantidadede de palavras dos tweets irrelevantes: $Qirr$\n",
    "Quantidade de palavras totais: $Qt$\n",
    "\n",
    "\n",
    "$$P(Relevante) = \\frac{Qr}{Qt}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$P(Irrelevante) = \\frac{Qirr}{Qt}$$\n",
    "\n",
    "\n",
    "Feito isso, vamos calcular as seguinte probabilidades: $P(Tweet|Relevante)$ e $P(Tweet|Irrelevante)$.\n",
    "\n",
    "Para calcular essas probabilidades √© necess√°rio separar as\n",
    "\n",
    "palavras de um determinado tweet, observar a frequ√™ncia absoluta de vezes que essa palavra aparece no total de palavras relevantes ou irrelevantes, e dividir pelo valor total de palavras que est√£o no conjunto de palavras relevantes ou irrelevantes. Ap√≥s feito isso √© necess√°rio multiplicar o valor obtido para cada palavra e assim temos a probabilidade $P(Tweet|Relevante ou Irrelevante)$ para um determinado tweet. Isso tudo gra√ßas a independ√™ncia de palavras do algoritmo Naive Bayes. Mas esse m√©todo tem um problema, e se a frequ√™ncia absoluta de uma determinada palavra for 0, ou seja, se ela n√£o estiver na nossa base de dados treinamento ?\n",
    "\n",
    "palavras de um determinado tweet, observar a frequ√™ncia absoluta de vezes que essa palavra aparece no total de palavras relevantes ou irrelevantes, e dividir pelo valor total de palavras que est√£o no conjunto de palavras relevantes ou irrelevantes. Ap√≥s feito isso √© necess√°rio multiplicar o valor obtido para cada palavra e assim temos a probabilidade $P(Tweet|Relevante ou Irrelevante)$ para um determinado tweet. Isso tudo gra√ßas a independ√™ncia de palavras do algoritmo Naive Bayes. Mas esse m√©todo tem um problema, e se a frequ√™ncia absoluta de uma determinada palavra for 0, ou seja, se ela n√£o estiver na nossa base de dados treinamento ?\n",
    "\n",
    "$$P(Palavra|Relevante) = \\frac{0 + 1}{Qr + Qtp}$$\n",
    "\n",
    "Sendo assim, n√≥s teremos uma f√≥rmula geral descrita da forma:\n",
    "\n",
    "Frequ√™ncia absoluta da palavra na lista de palavras relevantes: $Far$\n",
    "Frequ√™ncia absoluta da palavra na lista de palavras irrelevantes: $Fairr$\n",
    "\n",
    "\n",
    "$$P(Palavra|Relevante) = \\frac{Far + 1}{Qr + Qtp}$$\n",
    "\n",
    "\n",
    "O racioc√≠nio √© an√°logo para a lista irrelevante:\n",
    "\n",
    "\n",
    "\n",
    "$$P(Palavra|Irrelevante) = \\frac{Fairr + 1}{Qirr + Qtp}$$\n",
    "\n",
    "\n",
    "O Classificador de Naive Bayes se baseia na constru√ß√£o de um modelo bag-of-word. Na an√°lise de sentimento, queremos responder a seguinte pergunta: \"Qual a probabilidade dessa frase ser relevante, dado esse conjunto de palavras?\". Nesse sentido, √© necess√°rio computar esse c√°lculo utilizando probabilidades condicionais e o resultado do teorema de Bayes encontrado na sess√£o anterior:\n",
    "\n",
    "\\c\n",
    "Dessa forma, n√≥s vamos usar essa rela√ß√£o para encontrar $P(R|frase)$, ou seja, a probabilidade de uma frase ser relevante, dado o conjunto de palavras. Se quisermos encontrar essa probabilidade faremos a seguinte opera√ß√£o:\n",
    "$$P(R|frase) = \\frac{P(frase|R).P(R)}{P(frase)}$$\n",
    "Para prosseguir, utilizaremos um processo de \"Tokeniza√ß√£o\", que consiste em dividir a frase em peda√ßos menores (as palavras) e assumir que uma palavra n√£o influencia na coloca√ß√£o da outra. Sabemos que isso n√£o √© verdade, mas utilizaremos por quest√µes de simplifica√ß√£o (essa √© a ingenuidade do classificador de Naive Bayes)\n",
    "\n",
    "De forma an√°loga √© possivel encontrar:\n",
    "$$P(I|frase) = \\frac{P(frase|I).P(I)}{P(frase)}$$\n",
    "\n",
    "Agora, basta compararmos os valores das probabilidades:\n",
    "\n",
    "Se, $P(R|frase) > P(I|frase)$, ent√£o, √© mais prov√°vel que a frase seja $relevante$\n",
    "\n",
    "Caso contr√°rio, $P(R|frase) < P(I|frase)$, ent√£o, √© mais prov√°vel que a frase seja $irrelevante$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suaviza√ß√£o de Laplace para corrigir possiveis palavras fora da minha base de dados\n",
    "def smoothing(palavra, frequencia_absoluta, palavras_sem_repeticao, relevancia, alpha=1):\n",
    "    resultado = 0\n",
    "    try:\n",
    "        absoluta = frequencia_absoluta[palavra]\n",
    "    except:\n",
    "        absoluta = 0 #Se a palavra n√£o estiver na lista retorna 0\n",
    "    if relevancia == 'relevante':\n",
    "        resultado = (absoluta + alpha)/(len(palav_relev)+alpha*len(palavras_sem_repeticao))\n",
    "    elif relevancia == 'irrelevante':\n",
    "        resultado = (absoluta + alpha)/(len(palav_irrelev)+alpha*len(palavras_sem_repeticao))\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C√°lculo das Probabilidades condicionais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade para fazer a desigualdade \n",
    "def prob(relevancia,frase):\n",
    "    if relevancia == 'relevante':\n",
    "        probTweetdadoR = 1\n",
    "        for a in frase.split():\n",
    "            probTweetdadoR *= smoothing(a, rel_freq_abs, palavras_sem_repeticao, relevancia)\n",
    "        probRdadoTweet = P_rel * probTweetdadoR\n",
    "        return probRdadoTweet\n",
    "    elif relevancia == 'irrelevante':\n",
    "        probTweetdadoI = 1\n",
    "        for b in frase.split():\n",
    "            probTweetdadoI *= smoothing(b, irr_freq_abs, palavras_sem_repeticao, relevancia)\n",
    "        probIdadoTweet = P_irr * probTweetdadoI\n",
    "        return probIdadoTweet\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo de naive para comparar as probabilidades\n",
    "def Naive(tweet):\n",
    "    if prob('relevante',tweet) > prob('irrelevante',tweet):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Classificador\"]=train[\"Treinamento\"].apply(Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>namoral refrigerante melhor pepsip existe nenhum</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pepsi baseado gravidade sobre pepsi sentido ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qu√≠mica kalunga pepsi patrocinadores ficaram b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mataria refri geladinho pepsi geladeira</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dion√≠sio viciado pepsi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>queria fazer drink laranja beber pepsi mesmo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>minha falando pepsi caber geladeira ‚Äúgordinha‚Äù...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>triangular bread</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>acordei enjoo kerelho minha desculpa tomar cop...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>pessoas pepsi kkkkkk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relev√¢ncia  Modelo  \\\n",
       "0     namoral refrigerante melhor pepsip existe nenhum           1       1   \n",
       "1    pepsi baseado gravidade sobre pepsi sentido ne...           1       1   \n",
       "2    qu√≠mica kalunga pepsi patrocinadores ficaram b...           1       1   \n",
       "3              mataria refri geladinho pepsi geladeira           1       1   \n",
       "4                               dion√≠sio viciado pepsi           1       1   \n",
       "..                                                 ...         ...     ...   \n",
       "295       queria fazer drink laranja beber pepsi mesmo           0       0   \n",
       "296  minha falando pepsi caber geladeira ‚Äúgordinha‚Äù...           0       0   \n",
       "297                                   triangular bread           0       0   \n",
       "298  acordei enjoo kerelho minha desculpa tomar cop...           1       1   \n",
       "299                               pessoas pepsi kkkkkk           0       0   \n",
       "\n",
       "     Classificador  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "..             ...  \n",
       "295              0  \n",
       "296              0  \n",
       "297              0  \n",
       "298              1  \n",
       "299              0  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos foi de 52.67%\n",
      "A porcentagem de falsos positivos foi de 4.00%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos = train.loc[(train.Relev√¢ncia == 1) & (train.Classificador == 1), :].shape[0]\n",
    "falsos_positivos = train.loc[(train.Relev√¢ncia == 0) & (train.Classificador == 1), :].shape[0]\n",
    "\n",
    "print(f'A porcentagem de verdadeiros positivos foi de {100*verdadeiros_positivos/train.shape[0]:.2f}%')\n",
    "print(f'A porcentagem de falsos positivos foi de {100*falsos_positivos/train.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos foi de 43.00%\n",
      "A porcentagem de falsos positivos foi de 0.33%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos = train.loc[(train.Relev√¢ncia == 0) & (train.Classificador == 0), :].shape[0]\n",
    "falsos_negativos = train.loc[(train.Relev√¢ncia == 1) & (train.Classificador == 0), :].shape[0]\n",
    "\n",
    "print(f'A porcentagem de verdadeiros positivos foi de {100*verdadeiros_negativos/train.shape[0]:.2f}%')\n",
    "print(f'A porcentagem de falsos positivos foi de {100*falsos_negativos/train.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.67%\n"
     ]
    }
   ],
   "source": [
    "acuracia = 100*(verdadeiros_positivos+verdadeiros_negativos)/train.shape[0]\n",
    "print(f'{acuracia:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pepsi coisa outro mundo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pepsi arena ficar muito empresa droga controla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pepsi melhor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realizando pesquisa cient√≠fica amigos saber co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pizza tomando minha pepsi lim√£o melhorou humor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>querer chato pessoal parece nunca refrigerante...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>sonha pepsi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>dropei cocacola beber pepsi homenagem minha qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>esmagamento pepsi padr√£o a√ß√∫car sendo dif√≠cil ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>pedindo pepsi geladinha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relev√¢ncia  \\\n",
       "0                              pepsi coisa outro mundo           0   \n",
       "1    pepsi arena ficar muito empresa droga controla...           1   \n",
       "2                                         pepsi melhor           1   \n",
       "3    realizando pesquisa cient√≠fica amigos saber co...           0   \n",
       "4    pizza tomando minha pepsi lim√£o melhorou humor...           1   \n",
       "..                                                 ...         ...   \n",
       "195  querer chato pessoal parece nunca refrigerante...           1   \n",
       "196                                        sonha pepsi           0   \n",
       "197  dropei cocacola beber pepsi homenagem minha qu...           0   \n",
       "198  esmagamento pepsi padr√£o a√ß√∫car sendo dif√≠cil ...           1   \n",
       "199                            pedindo pepsi geladinha           0   \n",
       "\n",
       "     Classificador  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                1  \n",
       "..             ...  \n",
       "195              1  \n",
       "196              1  \n",
       "197              0  \n",
       "198              1  \n",
       "199              0  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Classificador\"] = test[\"Teste\"].apply(Naive)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos foi de 38.50%\n",
      "A porcentagem de falsos positivos foi de 28.00%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos = test.loc[(test.Relev√¢ncia == 1) & (test.Classificador == 1), :].shape[0]\n",
    "falsos_positivos = test.loc[(test.Relev√¢ncia == 0) & (test.Classificador == 1), :].shape[0]\n",
    "\n",
    "print(f'A porcentagem de verdadeiros positivos foi de {100*verdadeiros_positivos/test.shape[0]:.2f}%')\n",
    "print(f'A porcentagem de falsos positivos foi de {100*falsos_positivos/test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos foi de 19.00%\n",
      "A porcentagem de falsos positivos foi de 14.50%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos = test.loc[(test.Relev√¢ncia == 0) & (test.Classificador == 0), :].shape[0]\n",
    "falsos_negativos = test.loc[(test.Relev√¢ncia == 1) & (test.Classificador == 0), :].shape[0]\n",
    "\n",
    "print(f'A porcentagem de verdadeiros positivos foi de {100*verdadeiros_negativos/test.shape[0]:.2f}%')\n",
    "print(f'A porcentagem de falsos positivos foi de {100*falsos_negativos/test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.50%\n"
     ]
    }
   ],
   "source": [
    "acuracia = 100*(verdadeiros_positivos+verdadeiros_negativos)/test.shape[0]\n",
    "print(f'{acuracia:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No classificador que tem como objetivo de encontrar a relev√¢ncia dos tweets relacionas a marca Pepsi, como visto na acur√°cia foi obtido uma acur√°cia de ...%, com o percentual de ...% verdadeiros negativos e ...% falsos negativos.\n",
    "\n",
    "\n",
    "Por que n√£o podemos usar o pr√≥prio classificador para gerar mais amostras de treinamento?\n",
    "\n",
    "Nosso algoritmo de Naive Bayes a planilha de treinamento como algo que seja ideal para treinar o algoritmo,com isso tenta classificar outros tweets com base no que ela \"aprendeu\" observando a mesma. Isso faz com que esse classificador tenha problemas de classifica√ß√£o dado que se tem uma base pequena de dados para garantir a classifica√ß√£o dos demais. Para que fosse poss√≠vel gerar mais amostras seria necess√°rio ir atualizando a tabela treinamento para que o classificador aumente sua base de dados e fique mais preparado para classificar novos tweets de forma mais eficiente.\n",
    "\n",
    "Diferentes cen√°rios para Na√Øve Bayes\n",
    "\n",
    "Uma das principais utilidades do algoritmo de $Naive Bayes$ no contexto contempor√¢neo √© na distin√ß√£o de e-mails para poder filtrar os indesejados $spams$ e para qualificar textos baseando-se na frequ√™ncia de palavras usadas.\n",
    "\n",
    "O algoritmo de Naive Bayes pode ser utilizado para diminuir os acidentes de tr√¢nsitos. Com base nos movimentos oculares de motoristas que dirigiram cansados e guardando esses resultados em uma base de dados, seria poss√≠vel alertar aos motoristas quando eles estivessem cansados para que fizessem um descan√ßo antes de seguir viagem. Isso diminuiria dr√°sticamente os acidentes em rodovias.\n",
    "\n",
    "Uma outra utilidade para essa ferramenta seria na distin√ß√£o de mensagens suspeitas em redes socias para evitar os golpes virtuais que est√£o crescendo com o avan√ßo da tecnologia. O algoritmo seria capaz de identificar as palavras mais frequentes nesse estilo de mensagens e sinalizar o usu√°rio de que aquela mensagem tem um potencial risco de ser um golpe.\n",
    "\n",
    "Naive Bayes poderia tamb√©m ser usado para direcionamento de pesquisas na internet. Guardando palavras-chave na sua base de dados e direcionando publicidades que encaixam com o perfil do usu√°rio baseado no seu hist√≥rico de pesquisa.\n",
    "\n",
    "\n",
    "Cr√≠ticas e futuras itera√ß√µes:\n",
    "\n",
    "Para melhorar nosso classificador seria interessante trein√°-lo com diferentes tweets na base de treinamento. Para isso seria necess√°rio mesclar as planilhas de treinamento e teste, depois separ√°-las de forma aleat√≥ria e repetir o processo. Fazendo isso repetidas vezes seria poss√≠vel observar uma melhora na acur√°cia do nosso classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
